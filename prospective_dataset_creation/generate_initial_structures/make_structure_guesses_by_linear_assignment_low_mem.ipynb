{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw, Descriptors, rdmolfiles, rdMolAlign, rdmolops, rdchem, PyMol, Crippen, PropertyMol\n",
    "from rdkit import DataStructs\n",
    "from rdkit import RDLogger\n",
    "\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Geometry import Point3D\n",
    "from rdkit.Numerics.rdAlignment import GetAlignmentTransform\n",
    "from rdkit.Chem.AtomPairs import Pairs\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem import rdFMCS\n",
    "from rdkit.Chem import rdMolTransforms\n",
    "from tqdm import tqdm, trange\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import subprocess\n",
    "#import pmx\n",
    "import bz2\n",
    "import importlib\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "Bohr2Ang=0.529177249\n",
    "\n",
    "folder=os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the generated ligands from smiles strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "384481it [14:47, 433.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384481 384481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#construct generated ligands from smiles\n",
    "# refs=[]\n",
    "unique_smi=[]\n",
    "names=[]\n",
    "i=0\n",
    "with open(folder+\"/../cl13_detected_fragments_depth_3.smi\", \"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        s=line.strip()\n",
    "#         m=Chem.MolFromSmiles(s)\n",
    "#         m.SetProp('ID', f'set4_{i}')\n",
    "#         refs.append(m)\n",
    "        if(s not in unique_smi):\n",
    "            unique_smi.append(s)\n",
    "        names.append(f'set4_{i}')\n",
    "        i+=1\n",
    "# names=[mol.GetProp('ID') for mol in refs]\n",
    "\n",
    "print(len(names), len(unique_smi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter out ligands that are too large: >36 heavy atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_heavy_atoms(m):\n",
    "    n_heavy=0\n",
    "    for atom in m.GetAtoms():\n",
    "        if(atom.GetAtomicNum()>1):\n",
    "            n_heavy+=1\n",
    "    return(n_heavy)\n",
    "\n",
    "nHeavies=np.zeros(len(names))\n",
    "with open(folder+\"/../cl13_detected_fragments_depth_3.smi\", \"r\") as f:\n",
    "    for i,line in tqdm(enumerate(f)):\n",
    "        s=line.strip()\n",
    "        nHeavies[i]=get_num_heavy_atoms(Chem.MolFromSmiles(s))\n",
    "\n",
    "#del unique_smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"# Heavy Atoms\")\n",
    "plt.ylabel(\"# Ligands\")\n",
    "plt.hist(nHeavies, bins=int(np.ceil(np.max(nHeavies))-20), range=(20, np.ceil(np.max(nHeavies))), density=False)\n",
    "plt.vlines(36, 0, 40000, colors='k', linestyles='dashed', label='')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel=np.argwhere(nHeavies<=36)[:,0]\n",
    "print(len(sel))\n",
    "names_filtered=[names[i] for i in sel]\n",
    "# Draw.MolsToGridImage([Chem.MolFromSmiles(unique_smi[i]) for i in sel[::1000]], molsPerRow=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load reference crystal structure\n",
    "fn=folder+\"/4d09.mol\"\n",
    "xray_lig=rdmolfiles.MolFromMolFile(fn, sanitize=True, removeHs=False)\n",
    "xray_lig_name=\"4d09\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Draw.MolsToGridImage([xray_lig], legends=[xray_lig_name], molsPerRow=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chem.AddHs(xray_lig, addCoords=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to evaluate overlap of sidechains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_measure(molA, molB):\n",
    "    confA=molA.GetConformer()\n",
    "    confB=molB.GetConformer()\n",
    "    posA=[]\n",
    "    posB=[]\n",
    "    for i,a in enumerate(molA.GetAtoms()):\n",
    "        if(a.GetAtomicNum()>1): #not hydrogens\n",
    "            posA.append(list(confA.GetAtomPosition(i)))\n",
    "\n",
    "    for i,a in enumerate(molB.GetAtoms()):\n",
    "        if(a.GetAtomicNum()>1): #not hydrogens\n",
    "            posB.append(list(confB.GetAtomPosition(i)))\n",
    "    posA=np.array(posA)\n",
    "    posB=np.array(posB)\n",
    "    \n",
    "    dif=posA[:,np.newaxis,:]-posB[np.newaxis,:,:]\n",
    "    dist=np.linalg.norm(dif, axis=2)\n",
    "    A_ind, B_ind = linear_sum_assignment(dist)\n",
    "    measure = 0\n",
    "    for i,a in enumerate(A_ind):\n",
    "        measure+=dist[a, B_ind[i]]\n",
    "    return(measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align each ligand onto the closest X-ray structure based on common atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mapping(mol, ref, outpath, debug=False, dMCS=True):    \n",
    "    #remove old output files\n",
    "    for f in os.listdir(outpath):\n",
    "        os.remove(os.path.join(outpath, f))\n",
    "    \n",
    "    #dump files\n",
    "    mol_file=outpath+\"/mol.pdb\"\n",
    "    ref_file=outpath+\"/ref.pdb\"\n",
    "    with open(mol_file,\"w\") as f:\n",
    "        f.write(rdmolfiles.MolToPDBBlock(mol))\n",
    "    with open(ref_file,\"w\") as f:\n",
    "        f.write(rdmolfiles.MolToPDBBlock(ref))\n",
    "        \n",
    "    #map atoms with pmx\n",
    "    \n",
    "    # params\n",
    "    i1 = ref_file\n",
    "    i2 = mol_file\n",
    "    o1 = '{0}/ref_map.dat'.format(outpath)\n",
    "    o2 = '{0}/mol_map.dat'.format(outpath)\n",
    "    opdb1 = '{0}/out_pdb1.pdb'.format(outpath)\n",
    "    opdb2 = '{0}/out_pdb2.pdb'.format(outpath)\n",
    "    opdbm1 = '{0}/out_pdbm1.pdb'.format(outpath)\n",
    "    opdbm2 = '{0}/out_pdbm2.pdb'.format(outpath)\n",
    "    score = '{0}/score.dat'.format(outpath)\n",
    "    log = '{0}/mapping.log'.format(outpath)\n",
    "\n",
    "    if(dMCS):\n",
    "        process = subprocess.Popen(['pmx','atomMapping',\n",
    "                            '-i1',i1,\n",
    "                            '-i2',i2,\n",
    "                            '-o1',o1,\n",
    "                            '-o2',o2,\n",
    "                            '-opdb1',opdb1,\n",
    "                            '-opdb2',opdb2,                                        \n",
    "                            '-opdbm1',opdbm1,\n",
    "                            '-opdbm2',opdbm2,\n",
    "                            '-score',score,\n",
    "                            '-log',log,\n",
    "                            '--dMCS', '--d', '0.1',\n",
    "                            #'--RingsOnly'\n",
    "                                   ],\n",
    "                            stdout=subprocess.PIPE, \n",
    "                            stderr=subprocess.PIPE)\n",
    "        process.wait()\n",
    "    \n",
    "    if(not os.path.isfile(o2) ): #mapping failed, use less restrictive match criteria: no distance criterion in MCS\n",
    "        if(debug):\n",
    "            print(\"Initial atom mapping filed. Retrying without --dMCS\")\n",
    "#             raise()\n",
    "        process = subprocess.Popen(['pmx','atomMapping',\n",
    "                        '-i1',i1,\n",
    "                        '-i2',i2,\n",
    "                        '-o1',o1,\n",
    "                        '-o2',o2,\n",
    "                        '-opdb1',opdb1,\n",
    "                        '-opdb2',opdb2,                                        \n",
    "                        '-opdbm1',opdbm1,\n",
    "                        '-opdbm2',opdbm2,\n",
    "                        '-score',score,\n",
    "                        '-log',log,\n",
    "                               ],\n",
    "                        stdout=subprocess.PIPE, \n",
    "                        stderr=subprocess.PIPE)\n",
    "        process.wait()\n",
    "    \n",
    "    if(not os.path.isfile(o2) ):\n",
    "        raise RuntimeError('atomMapping failed after a second, less restrictive, attempt.')\n",
    "    \n",
    "    #read mapping: indeces of mol ordered as ref\n",
    "    mol_inds=[]\n",
    "    ref_inds=[]\n",
    "    with open(o2,\"r\") as f:\n",
    "        for line in f:\n",
    "            m,r=line.split()\n",
    "            mol_inds.append(int(m)-1)\n",
    "            ref_inds.append(int(r)-1)\n",
    "            \n",
    "    #the above mapping is in output atom order\n",
    "    #pmx atomMapping can change the order from the input one though.\n",
    "            \n",
    "    with open(score,\"r\") as f:\n",
    "        for line in f:\n",
    "            score_val=float(line.split()[-1])\n",
    "            break;\n",
    "            \n",
    "    return(mol_inds, ref_inds, score_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all ligand structures in a parallel manner using owl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. input files\n",
    "Save (xray, scaffold=Null, ref) tupples as separate pickles for each ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite=False\n",
    "\n",
    "xray = Chem.AddHs(xray_lig, addCoords=True)\n",
    "os.makedirs(folder+'/lig_structures/', exist_ok=True)\n",
    "\n",
    "#loop over ligands most similar to this xray structure\n",
    "for i, ref_id in enumerate(trange(len(refs))):\n",
    "    ref  = refs[ref_id]\n",
    "    fname=folder+'/lig_structures/{}.pickle'.format(ref.GetProp('ID'))\n",
    "    if(not os.path.isfile(fname) or overwrite):\n",
    "        scaffold = None\n",
    "        if(ref.HasProp('embedded')):\n",
    "            ref.ClearProp('embedded')\n",
    "        pickle.dump( (xray, scaffold, PropertyMol.PropertyMol(ref)), open( fname, \"wb\" ) )\n",
    "gc.collect()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload ligands from the pickle files\n",
    "def reload_refs_from_pickles():\n",
    "    for i, ref_id in enumerate(trange(len(refs))):\n",
    "        ref  = refs[ref_id]\n",
    "        fname=folder+'/lig_structures/{}.pickle'.format(ref.GetProp('ID'))\n",
    "        if(os.path.isfile(fname)):\n",
    "            xray, scaffold, ref = pickle.load( open( fname, \"rb\" ) )\n",
    "            refs[ref_id] = ref\n",
    "    print(\"Done reloading\")\n",
    "reload_refs_from_pickles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259901/259901 [00:00<00:00, 3040871.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for n in tqdm(names):\n",
    "    fname=folder+'/lig_structures/{}.pickle'.format(n)\n",
    "    if(os.path.isfile(fname)):\n",
    "        ref = pickle.load( open( fname, \"rb\" ) )[2]\n",
    "\n",
    "        if(ref.HasProp('embedded') and ref.GetProp('embedded')==\"yes\"):\n",
    "            continue; #already handled\n",
    "        elif(ref.HasProp('corrupt') and ref.GetProp('corrupt')==\"yes\"): #corrupt rings from incorrect ring colosure numbers in SMILES\n",
    "            continue; #already handled\n",
    "        names_left.append(n)\n",
    "\n",
    "pickle.dump( names_left, open( folder+\"/set_4_lig_names_still_to_embed.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2B. run embedding (on owl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/129223 [00:00<08:46, 245.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Queue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129223/129223 [05:30<00:00, 390.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previously_done: 73359 \t out of: 129223\n",
      "ligands left: 55864 \t # workers: 600 \t # ligands/worker: 94 \t estimated completition time: 94 min\n",
      "queue size: 55864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "exceptions must derive from BaseException",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-85560f8ae083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mworker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Submitting.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: exceptions must derive from BaseException"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import threading\n",
    "\n",
    "previously_done=0\n",
    "max_debug_evals=200000\n",
    "\n",
    "# print(\"Reloading ligands.\")\n",
    "# reload_refs_from_pickles()\n",
    "\n",
    "q = queue.Queue()\n",
    "print(\"Building Queue.\")\n",
    "for n in tqdm(names_filtered):\n",
    "    if (not n in names_left):\n",
    "        previously_done+=1\n",
    "        continue\n",
    "    fname=folder+'/lig_structures/{}.pickle'.format(n)\n",
    "    if(os.path.isfile(fname)):\n",
    "        ref = pickle.load( open( fname, \"rb\" ) )[2]\n",
    "\n",
    "        if(ref.HasProp('embedded') and ref.GetProp('embedded')==\"yes\"):\n",
    "            previously_done+=1\n",
    "            continue; #already handled\n",
    "        elif(ref.HasProp('corrupt') and ref.GetProp('corrupt')==\"yes\"): #corrupt rings from incorrect ring colosure numbers in SMILES\n",
    "            previously_done+=1\n",
    "            continue; #already handled\n",
    "        fname=folder+'/lig_structures/{}.pickle'.format(ref.GetProp('ID'))\n",
    "        q.put(fname)\n",
    "\n",
    "        if(q.qsize()>=max_debug_evals):\n",
    "            break;\n",
    "        \n",
    "print(\"previously_done:\", previously_done, \"\\t out of:\", len(names_filtered), flush=True)\n",
    "nligs_left=len(names_filtered)-previously_done\n",
    "nligs_left=min(nligs_left, max_debug_evals)\n",
    "nworkers=600\n",
    "nligs_per_worker=int(np.ceil(float(nligs_left)/nworkers))\n",
    "print(\"ligands left:\", nligs_left, \"\\t # workers:\", nworkers, \"\\t # ligands/worker:\", nligs_per_worker,\n",
    "      \"\\t estimated completition time:\", nligs_per_worker, \"min\")\n",
    "print(\"queue size:\", q.qsize(), flush=True)\n",
    "\n",
    "#raise()\n",
    "\n",
    "os.makedirs(folder+'/lig_structures/', exist_ok=True)\n",
    "\n",
    "# #remove old jobscripts\n",
    "# print(\"Deleting old jobscripts\")\n",
    "# process = subprocess.Popen(['rm', folder+\"/lig_structures_jobscripts/jobscript_*\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "# process.wait()\n",
    "# print(process.stdout.read().decode(\"utf-8\"))\n",
    "# print(process.stderr.read().decode(\"utf-8\"))\n",
    "# print(\"Finished deleting old jobscripts\")\n",
    "# # raise()\n",
    "\n",
    "cwd=folder+\"/lig_jobscripts/\"\n",
    "cmd_str=\"source /etc/profile; module load sge; cd {};\".format(cwd)\n",
    "\n",
    "def worker(job_id):\n",
    "#     print(\"worker\", job_id)\n",
    "    ligands_str=\"\"\n",
    "    for l in range(nligs_per_worker):\n",
    "        fname = q.get()\n",
    "        if fname is None:  # EOF?\n",
    "            break\n",
    "        ligands_str+=\" \"+fname\n",
    "    if(not ligands_str):\n",
    "        return # skip writing jobscript if it will not handle any ligands\n",
    "    jobscript_str=f\"\"\"\n",
    "#!/bin/bash\n",
    "#$ -S /bin/bash\n",
    "#$ -pe openmp_* 1\n",
    "#$ -q *\n",
    "#$ -N lig_struct_gen_{job_id}\n",
    "#$ -M ykhalak@gwdg.de\n",
    "#$ -m n\n",
    "#$ -l h_rt=4:00:00\n",
    "#$ -wd {cwd}\n",
    "\n",
    "cd $TMPDIR\n",
    "\n",
    "source ~/.ML_profile\n",
    "python {folder}/embed_script.py -f {ligands_str}\n",
    "\"\"\"\n",
    "    jobscript_fn=cwd+\"/jobscript_{}\".format(job_id)\n",
    "    with open(jobscript_fn,\"w\") as f:\n",
    "        f.write(jobscript_str)\n",
    "        \n",
    "                \n",
    "    global cmd_str\n",
    "    cmd_str+=\" qsub {};\".format(jobscript_fn)\n",
    "\n",
    "#     ssh_cmd_arr=[\"ssh\", \"owl\", \"source /etc/profile; module load sge; cd {}; qsub {};\".format(cwd, jobscript_fn)]\n",
    "#     process = subprocess.Popen(ssh_cmd_arr, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "#     process.wait()\n",
    "\n",
    "\n",
    "for job_id in range(nworkers):\n",
    "    q.put(None)\n",
    "    worker(job_id)\n",
    "    \n",
    "# raise()\n",
    "    \n",
    "print(\"Submitting.\")\n",
    "ssh_cmd_arr=[\"ssh\", \"owl\", cmd_str]\n",
    "process = subprocess.Popen(ssh_cmd_arr, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "process.wait()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# print(\"Submitting.\")\n",
    "# ssh_cmd_arr=[\"ssh\", \"owl\", cmd_str]\n",
    "# process = subprocess.Popen(ssh_cmd_arr, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "# process.wait()\n",
    "# print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. check how many ligands are finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129223/129223 [10:54<00:00, 197.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previously_done: 129223 \t out of: 129223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrupt: 0\n",
      "unfinished: 259901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previously_done=0\n",
    "n_corrupt=0\n",
    "#unfinished_pIC50=[]\n",
    "#unfinished_refs_ids=[]\n",
    "names_left=[]\n",
    "\n",
    "for ref_id,n in enumerate(tqdm(names_filtered)):\n",
    "    fname=folder+'/lig_structures/{}.pickle'.format(n)\n",
    "    if(os.path.isfile(fname)):\n",
    "        ref = pickle.load( open( fname, \"rb\" ) )[2]\n",
    "        if(ref.HasProp('embedded') and ref.GetProp('embedded')==\"yes\"):\n",
    "            previously_done+=1\n",
    "            continue; #already handled\n",
    "        elif(ref.HasProp('corrupt') and ref.GetProp('corrupt')==\"yes\"): #corrupt rings from incorrect ring colosure numbers in SMILES\n",
    "            previously_done+=1\n",
    "            n_corrupt+=1\n",
    "            continue; #already handled\n",
    "        else:\n",
    "            #unfinished_refs_ids.append(ref_id)\n",
    "            names_left.append(n)\n",
    "\n",
    "\n",
    "\n",
    "print(\"previously_done:\", previously_done, \"\\t out of:\", len(names_filtered), flush=True)\n",
    "print(\"corrupt:\", n_corrupt)\n",
    "print(\"unfinished:\", len(names_left))\n",
    "\n",
    "# print(unfinished_refs_ids)\n",
    "    \n",
    "pickle.dump( names_left, open( folder+\"/set_4_lig_names_still_to_embed.pickle\", \"wb\" ) )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previously_done: 129223 \t out of: 384481\n",
      "corrupt: 0\n",
      "unfinished: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"previously_done:\", previously_done, \"\\t out of:\", len(names), flush=True)\n",
    "print(\"corrupt:\", n_corrupt)\n",
    "print(\"unfinished:\", len(names_left))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save all sucessfully embedded ones as a pickle dataset.\n",
    "Not all lignads embeded sucessfully. So we only use the ones that did and further filter out any that are too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129223/129223 [00:19<00:00, 6682.41it/s]\n",
      "  1%|          | 705/129223 [00:00<00:18, 7047.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 129223 ligands out of a total 384481 SMILES.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129223/129223 [00:18<00:00, 7131.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 129223 neutral ligands out of a total 384481 SMILES.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ligs_to_save=[]\n",
    "for n in tqdm(names_filtered):\n",
    "    fname=folder+'/lig_structures/{}.pickle'.format(n)\n",
    "    if(os.path.isfile(fname)):\n",
    "        l = pickle.load( open( fname, \"rb\" ) )[2]\n",
    "        if( l.HasProp('embedded') and l.GetProp('embedded')==\"yes\" and not (l.HasProp('corrupt')) ):\n",
    "            ligs_to_save.append(l)\n",
    "\n",
    "pickle.dump( ligs_to_save, open( folder+\"/set_4_filtered_embedded.pickle\", \"wb\" ) )\n",
    "print(f\"Saved {len(ligs_to_save)} ligands out of a total {len(names)} SMILES.\")\n",
    "gc.collect()\n",
    "\n",
    "ligs_to_save=[]\n",
    "for n in tqdm(names_filtered):\n",
    "    fname=folder+'/lig_structures/{}.pickle'.format(n)\n",
    "    if(os.path.isfile(fname)):\n",
    "        l = pickle.load( open( fname, \"rb\" ) )[2]\n",
    "        if( l.HasProp('embedded') and l.GetProp('embedded')==\"yes\" and (Chem.rdmolops.GetFormalCharge(l)==0) ):\n",
    "            ligs_to_save.append(l)\n",
    "pickle.dump( ligs_to_save, open( folder+\"/set_4_filtered_embedded_neutral_only.pickle\", \"wb\" ) )\n",
    "print(f\"Saved {len(ligs_to_save)} neutral ligands out of a total {len(names)} SMILES.\")\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
